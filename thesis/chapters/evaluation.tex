%!TEX root = ../dissertation.tex

\chapter{Evaluation}
\label{chapter:evaluation}

In order to evaluate our system we start by looking at its core focus, its
eventual delivery guarantees and overall performance. We not only test our
system by itself but we also compare it with the current solution tied to
libp2p, entitled floodsub. To do this we rely on the tools previously described
in chapter \ref{chapter:implementation}. 

Afterwards we seek to evaluate  Pulsarcast's new functionality, such as the
ability to rebuild our topic stream history through data immutability and
persistence.

\section{Dataset}\label{dataset}

To test our system accordingly, we wanted a dataset that could simulate a real
life scenario as much as possible. We chose to use a dataset of
Reddit's~\footnote{https://www.reddit.com/} comments from
2007~\footnote{http://academictorrents.com/details/7690f71ea949b868080401c749e878f98de34d3d}~\footnote{\url{https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_reddit_comment/}} consisting of a sample of approximately 25000 comments in a total of 23 topics (known as sub-reddits in the platform). For the purpose of our test runs, we used the comments as events to be injected in our system and the sub-reddits as the topics in which these were published.


\subsection{Filtering and Normalisation}\label{subsec:filtering}

Our dataset consisted in line separated JSON structures, each describing a
comment. Given the large set of data, we started by sampling a set of 25000
messages.  Following this we needed to first, remove comments from unknown
users (users that had deleted the account at the time when the comments were
scrapped), followed by normalising our user number (reduce the number of
publishers in the dataset to the number of active nodes in our pulsarcast
system), as well as correlating all of our data. We ended up creating a CLI
tool that consumed data from this dataset and generated a document of multiple
JSON objects separated by
newlines~\footnote{https://github.com/JGAntunes/pulsarcast-test-harness}, ready
to be used by our ipfs-testbed-cli, described in chapter
\ref{chapter:implementation}. Examples of the output produced can be seen in
\ref{dataset-output}

\begin{lstlisting}[language=JSON, float, caption={Data example to be used in testbed},label={dataset-output}]
// Topic
{
  "type": "topic",
  "node": "node-71",
  "name": "reddit.com",
  "author": "test-user",
  "totalNumberEvents": 1
}

// User
{
  "type": "user",
  "name": "foobar",
  "node": "node-71",
  "events": [
    {
      "internalId": 0,
      "topic": "reddit.com",
      "body": "test",
      "ups": 1,
      "downs": 0,
      "controversiality": 0
    },
    {
      "internalId": 176,
      "topic": "reddit.com",
      "body": "test-123",
      "ups": 1,
      "downs": 4,
      "controversiality": 0
    }
  ],
  "subscriptions": {
  	"reddit.com": true,
  	"politics": true,
  	"business": true,
	}
}
\end{lstlisting}

\section{Testbed configuration}\label{testbed-configuration}

Our test runs were designed to be performed in managed infrastructure (commonly
known as cloud services). For the initial runs and general fine tuning of the
platform we relied in Google Cloud's managed Kubernetes solution. Later on, and
for our actual test executions, we ran all of our tests in Microsoft's Azure
Kubernetes solution, thanks to Microsoft and the Azure team we were kind enough
to support our efforts and offer us free credits.

Our whole setup consisted of a total of 5 VMs acting as Kubernetes Worker
nodes, each with 2 vCPUs, 16 GiB of RAM and 32 GiB of storage. In our cluster,
besides other operational bits, we ran 3 Elasticsearch instances, 1 Logstash
instance, 1 Kibana and a total of 100 IPFS Testbed deployments (as described in
chapter \ref{chapter:implementation}). Because we wanted to avoid resource
starvation and to better take advantage of the Kubernetes scheduler, our
testbed deployments allocate 440 MiB per deployment, each burstable to a
maximum of 500 MiB. During our whole test execution, periodic HTTP health
checks (part of the Kubernetes platform) make sure our deployments are working
accordingly.

Test executions are managed through a single machine, from where all the
commands are sent. During execution, a max of 5 commands are performed in
parallel, with a slight 10 millisecond delay added between each bulk
execution. All the requests are subject to retries, in case of failure, to a
maximum of 5 attempts, after which the failure is registered and the execution
moves on.

\section{Metrics}\label{metrics}

For each execution we look to extract two key groups of data. Resource usage
data and QoS data. The following list describes these in more detail:

\begin{itemize}
  \item Resource usage as a total in the whole cluster, and per node (95/99
  percentile and average)
  \begin{itemize}
    \item CPU Usage (CPU number)
    \item Memory Usage (GiB)
    \item Network Usage (MiB transmitted)
  \end{itemize}
  \item QoS
  \begin{itemize}
    \item Events published by topic and in total
    \item Events received by topic and in total
    \item Percentage of subscriptions fulfilled based on the number of events
    successfully published
    \item Percentage of subscriptions fulfilled based on the number of events
    initially injected in the system
    \item Number of RPC messages sent per topic and in total
    \item Average, standard deviation and percentiles (99/95) of RPC messages
    sent by node
  \end{itemize}
\end{itemize}

It's important to keep in mind that some of the metrics under the QoS group
only make sense in Pulsarcast test runs, hence will be ignored when running the
baseline Floodsub solution.

\section{Executions}\label{executions}

\section{Results}\label{results}
